20 Nginx的请求处理流程
-----------------------------------

(1)为什么讨论nginx的架构基础
nginx运行在企业的边缘节点,他处理的流量是应用服务器处理流量的数倍,甚至几个数量级
任何一种问题在不同数量级下的解决方案是不同的.所以在nginx处理场景中,任何一种问题都会被放大

为什么nginx采用master-worker架构模型?
为什么worker进程数量和cpu核数相匹配?
需要在多个worker间共享数据时候,为什么在TSL,或者一些限流限速场景,他们的共享方式是有所不同的?

Nginx请求处理流程:

(1)为什么称为状态机?
因为nginx使用非阻塞的事件驱动处理引擎(epoll),使用异步处理引擎需要使用状态机识别请求和处理

[1]处理4层TCP/UDP的传输层状态机
[2]处理应用的http状态机
[3]处理邮件Mail状态机

(2)每一种状态机在解析出请求,需要访问静态资源时候,对反向代理内容可以做磁盘缓存(proxy_pass,proxy_cache)
处理静态资源问题:当整个内存已经不足以完全缓存住所有的文件,缓存信息,sendfile,aio调用退化为阻塞的磁盘调用,使用线程池处理磁盘阻塞调用

对于每一个处理完的请求,记录access,error日志,记录在磁盘中,也可以通过syslog协议记录在远程机器
Nginx作为负载均衡,反向代理,把请求通过协议级传输后面的服务器,也可以通过应用层协议FastCGI,uWSGI,SCGI(python)代理到应用服务器


21 Nginx的进程结构
-----------------------------------
1.单进程:不适用于生产环境,只适用于开发调试
2.多进程:生成环境保证Nginx足够健壮,Nginx利用多核的特性
父进程:Master Process,子进程:cache,worker进程

为什为多进程结构,不是多线程?
Nginx要保证高可用性,高可靠性.如果使用多线程,线程之间共享同一块地址空间.当一个第三方模块引发一个地址空间导致
段错误时候,会导致整个nginx进程全部挂掉.采用多进程往往不会出现这个问题
第三方模块一般不会在Master Process加入自己代码,Master进程目的worker进程管理,所有的worker进程处理请求,

Master进程监控每个worker进程是否在工作,需不需要载入配置文件,需不需要做热部署
Cache缓存需要在多个Worker进程间共享,还被Cache Manager,Cache Loader进程使用
Cache Manager,Cache Loader为反向代理时候,后端发来的动态请求 做缓存所使用
Cache Loader作为缓存载入
Cache Manager作为缓存管理
这些进程间通信使用共享内存

为什么work进程很多?
Nginx采用事件驱动模型,希望每一个worker进程从头到尾,占有一颗cpu,不仅仅把worker进程数量配置和cpu合数一样
,还需要把每个cpu核与worker进程绑定,可以更好使用每一颗cpu上的cpu缓存,来减少缓存失效命中率

22 Nginx的进程结构实例演示
-----------------------------------
master作为父进程启动很多子进程,Nginx父子进程通过信号管理
ps -ef | grep nginx 看见当前进程id,和进程id
(1)./nginx -s reload把之前的worker,cache进程优雅退出,然后使用新的配置项,启动新的worker进程
reload与SIGHUP信号相同
kill -SIGHUP `cat nginx/logs/nginx.pid`
(2)向worker进程发送退出信号SIGQUIT,SIGINT,SIGTERM,worker进程退出向父进程master发送SIGCHILD信号,master进程知道子进程
退出了,重启一个worker进程

23 使用信号管理Nginx的父子进程
-----------------------------------

Nginx是一个多进程的程序,多进程通信可以使用共享内存,信号等
进程间管理使用信号
Master进程:
(1)监控worker进程CHILD,如果worker模块由于出现bug导致worker进程意外终止,master进程可以立刻通过CHILD信号,
重新把worker进程拉起
(2)接收信号管理worker进程,
TERM,INT立刻停止nginx进程
QUIT优雅停止nginx进程,保证对用户不发送立刻结束连接,不发送TCP-RESET复位请求报文
HUP重载配置文件
USR1重新打开日志文件,做日志文件切割
USR2
WINCH:热部署关闭老的worker进程

为什么不直接对work进程发送信号?
希望通过master进程管理worker进程
work进程
(1)接收信号TERM,INT,QUIT,USR1,WINCH

nginx命令行
启动nginx后,nginx把pid记在logs/nginx.pid,文件中记录master进程pid
执行./nginx -s 命令行,读取pid文件中master进程pid,向进程发送信号
reload:HUP
reopen:USR1
stop:TERM
quit:QUIT

24.reload重载配置文件的真相
-----------------------------------

情况:发现nginx的worker进程数量变多了,因为老配置运行nginx的worker长时间没有退出

(1)向master进程发送HUP信号(reload 命令)
(2)master进程校验配置语法是否正确
(3)master进程打开新的监听端口(子进程会继承父进程打开的所有端口)
(4)master进程用新配置启动新的worker子进程
(5)master进程向老worker子进程发送QUIT信号
(6)老worker进程关闭监听句柄(标志新的连接只会到新的worker),处理完当前连接结束进程

不停机载入新配置,nginx始终保持运行中,平滑的更换了配置文件 
(1)更新nginx.conf配置文件,向Master发送SIGHUP信号或者执行nginx -s reload
(2)Master使用新配置启动新的worker进程
(3)老配置Worker进程在完成已存在连接是优雅的退出

有一些请求出问题,client长时间没有处理,导致请求长时间占用在worker进程上,这个worker进程一直存在,
worker_shutdown_timeout最长会等多长时间,master在启动新的woker子进程时,加上一个定时器,老worker在超时,会强制退出

25.热升级的完整流程
-----------------------------------

热升级流程
(1)将旧Nginx文件换成新Nginx文件(注意备份)
    新编译的nginx所指定配置选项,比如配置目录,log目录必须和老nginx一样
    cp -f nginx nginx.old
(2)向master进程发送USR2信号
       [1]master进程修改pid文件名,加后缀.oldbin
       [2]master进程用新Nginx文件启动新master进程,新的master进程是老master的子进程
       (中间过程,新老nginx进程并存,同时处理请求,然后老master关闭监听端口)
(3)向老master进程发送WINCH信号,关闭老worker
(老的master进程保存下来方便会滚)
(4)[1]回滚:向老master发送HUP,向新master发送QUIT
   [2]向老master进程发送SIGQUIT信号,要求它优雅的停止 


26 优雅地关闭worker进程
-------------------------------------
(1)设置定时器worker_shutdown_timeout
(2)关闭监听句柄
(3)闭空闲连接(看nginx连接池,nginx保证资源利用最大化,经常保存一些连接,没有断开)
(4)在循环中等待全部连接关闭,或者等到worker_shutdown_timeout时间立即退出
(5)退出进程 

如果我们在处理连接的时候,不管连接此时是怎样的作用,直接关闭连接,会导致用户收到错误
优雅的关闭:(1)只nginx可以识别出当前的连接没有正在处理请求,这时把连接关闭
           (2)有些情况nginx做不到,
               比如nginx代理websocket协议,websocket后面通讯的fram帧里面,nginx不解析帧
               nginx做tcp/udp反向代理,nginx没有办法识别需要经过多少报文才算是结束
               主要是针对http请求
                                  
在特性失效时候考虑nginx有无能力判定一个连接应当被正确关掉
或者说一些模块,或客户端不能正常处理请求时,nginx需要有一些措施,比如worker_shutdown_timeout保证worker进程退出

27 网络收发与Nginx事件间的对应关系
---------------------------------------

事件->网络事件

应用层发起get请求
传输层,浏览器打开端口,把端口记下来,把nginx打开的端口记录在传输层
网络层我的主机ip,以及nginx所在服务器公网ip
链路层
路由器,会记录我家所在运营商的ip

网络报文角色:
数据链路层在HEADER和FOOTER添加MAC地址,源MAC地址,目的MAC地址
网络层:源IP地址,nginx公网地址(目的IP地址),MTU以太网1500K
传输层:浏览器打开的端口,nginx端口,TCP层考虑中间每一个环节最大MTU值,MSS
应用层:http协议

读事件
(1)请求建立TCP连接事件
(2)TCP连接可读事件
(3)TCP连接关闭事件
写事件:nginx需要向浏览器发送响应,需要把消息写到操作系统中,要求操作系统发到网路中
异步处理时间框架中:事件收集分发器,定义每一个事件的消费者,事件是生产者
读消息写消息,在http状态机,不同时间段调用不同方法


28 Nginx网络事件实例演示
---------------------------------------

29 Nginx的事件驱动模型
-----------------------------------------

WAIT FOR EVENTS ON CONNECTIONS
等待事件:比如客户端连接nginx,对应epoll_wait方法,nginx处理sleep状态
当操作系统收到一个TCP建立连接的握手报文,并且处理完握手流程以后,操作系统通知epoll_wait阻塞方法,唤醒nginx的worker进程
    |
   \|/
REVEIVE QUEUE OF NW EVENTS <----- KERNEL
找操作系统要事件,操作系统把事件放在事件队列中
    |                               /|\
   \|/                               |
PROCESS THE EVENT QUEUE IN CYCLE------
处理事件循环 

                        No
IS EVENTS QUEUE EMPTY -------> QUEUE
事件队列不为空,取出事件,处理事件
处理事件过程中可能会生成新的事件,比如一个连接新建立,需要添加一个超时时间,默认60s,如果浏览器不像我发送请求,关闭连接
比如收完完整http请求,可以生成http响应,需要向操作系统写缓冲区,要求操作系统把缓冲区内容发送给浏览器

如果所有事件处理完回到WAIT FOR EVENTS ON CONNECTIONS

一些第三方模块大量运算,处理一个事件非常长,会导致后续队列中大量事件长时间得不到处理,从而引发恶性循环
大量cpu,nginx任务都消耗在处理连接不正常断开,所以nginx不能容忍第三方模块长时间消耗大量cpu进行计算任务
比如gzip不会一次使用大量cpu,都是分段适用的


30 epoll的优劣及原理
------------------------------------

比如nginx要处理100w连接,每两次在等待连接中,时间可能非常短,短短几百ms所能收到的报文数量是有限的,有限的事件对应
的连接也是有限的(每次处理时间时,虽然有100W个并发连接,可能直接接收到几百个活跃连接)
select,poll每次在取操作系统事件时,把这100W个连接扔给操作系统,让它一次判断哪些连接有事件进来,
操作系统做了无用功,扫描了大量无用连接
epoll利用这个特性,每次处理活跃连接占比很小
nginx每次取活跃连接时,只需遍历一个链表,这个链表仅仅只有活跃的连接
比如:nginx收到80端口建立连接请求,80端口建立成功后,添加一个读事件,用于读取http消息,事件添加到一个红黑树中,
二叉平衡树插入效率O(log(n)),如果现在不想处理读事件,写事件,从平衡二叉树移除节点
读取一个事件链表数量减少,当操作系统从网卡接收到发来的报文链表增加


31 Nginx的请求切换
-----------------------------------------

事件驱动对于请求切换的收益
