hadoop
----------------
    1.独立模式(standalone|local)
        nothing!
        本地文件系统。
        不需要启用单独进程。
    2.pesudo(伪分布式模式)
        等同于完全分布式,只有一个节点。
        SSH:       //(socket)
                   // public + private
                   // server : sshd ps -Af | grep sshd
                   //client : ssh
                   // ssh-keygen:生成公私秘钥
                   // authorized_keys 需要使用644
                   // ssh localhost yes
        (配置文件)
            core-site.xml  //fs.defaultFS=hdfs://localhost/
            hdfs-site.xml  //replication=1
            mapred-site.xml
            yarn-site.xml

    3.full distrubuted(完全分布式)

让命令行提示符显示完整路径
    1.编辑profile文件，添加环境变量
    [/etc/profile]
    export PS1='[\u@\h `pwd`]'

配置hadoop，使用符号连接的方式，让三种配置形态共存,
--------------------------------------------------
    1.创建三个配置目录,内容等同于hadoop目录
        $(hadoop_home)/etc/local
        $(hadoop_home)/etc/pesudo
        $(hadoop_home)/etc/full
    2.创建符号连接
        $>ln -s 
    3.对hdfs进行格式化
        $>hadoop namenode -format
    4.修改hadoop配置文件，手动指定JAVA_HOME环境变量
        [#{hadoop_home}/etc/hadoop/hadoop_env.sh]
        ...
        export JAVA_HOME=/soft/jdk
        ...
    5.启动hadoop的所有进程
        $>start-all.sh 
    6.启动完成后，出现以下进程
        $>jps 查看
            15856 ResourceManager
            15956 NodeManager
            16469 Jps
            15334 NameNode
            15703 SecondaryNameNode
            15435 DataNode
    7.查看hdfs文件系统
        $>hdfs dfs -ls
        15856 ResourceManager
        15956 NodeManager
        16469 Jps
        15334 NameNode
        15703 SecondaryNameNode
        15435 DataNode
    8.创建目录
        $>hdfs dfs -mkdir -p /user/liuqi15/hadoop
    9.通过webui查看hadoop的文件系统
        http://localhost:50070/
    10.停止hadoop所有进程
        $>stop-all.sh
    11.centos防火墙操作
        [centos 6.5之前版本]
        $>sudo service firewalld stop    // 停止服务
        $>sudo service firewalld start    // 启动服务
        $>sudo service firewalld status    // 查看状态
        
        [centos7]
        $>sudo systemctl enable firewalld.service    // 启用
        $>sudo systemctl disable firewalld.service    // 禁用
        $>sudo systemctl start direwalld.service    // 启动
        $>sudo systemctl stop firewalld.service    // 停止
        $>sudo systemctl status firewalld.service    // 查看状态

hadoop的端口
---------------------
    50070    //namenode http port
    50075    //datanode http port
    50090    /2namnode http port

    8020     //namenode rpc port
    50010    //datanode rpc port
hadoop四大模块
    common
    hdfs   //namenode + datanode +secondarynamenode
    mapred
    yarn   // resourcemanager + nodemanager
启动脚本
--------------------
    1.start-all.sh     // 启动所有进程
    2.stop-all.sh    // 停止所有进程
    3.start-dfs.sh
    4.start-yarn.sh
    [hdfs] start-dfs.hs stop-dfs.sh
        NN
        DN
        2NN
    [yarn] start-yarn.sh stop-yarn.sh
        RM
        NM

修改主机名
------------------
    1./etc/hostname
        s201
    2./etc/hosts
        127.0.0.1 localhost
        192.168.231.201 s201
        192.168.231.202 s202
        192.168.231.203 s203
        192.168.231.204 s204

完全分布式
-------------------
    1.克隆3台client(centos)
        右键centos-7-->管理->克隆->...->完整克隆
    2.启动client
    3.启用客户机共享文件夹
    4.修改hostname和ip地址文件
        [/etc/hostname]
        s202
        [/etc/sysconfig/network-scripts/ifcfg-ethxxx]
        ...
        IPADDR=...
    5.重启网络服务
        $>sudo service network restart
    6.修改/etc/resolv.conf文件
        nameserver 192.168.231.2
    7.重复3~6过程

准备完全分布式主机的ssh
------------------
    1.删除所有主机的/home/centos/.ssh/*
    2.在s201主机上生成密钥对
        $>ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
    3.将s201的公钥文件id_rsa.pub远程复制到s202~s204主机上,
      并放置/home/centos/.ssh/authorized_keys
      $>scp id_rsa.pub centos@s202:/home/centos/.ssh/authorized_keys
      $>scp id_rsa.pub centos@s203:/home/centos/.ssh/authorized_keys
    4.配置完全分布式(${hadoop_home}/etc/hadoop/})
      [core-site.xml]
      fs.defaultFS=hdfs://s201/
      [hdfs-site.xml]
      <?xml version="1.0" encoding="UTF-8"?>
      <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
      <configuration>
          <property>
              <name>dfs.replication</name>
              <value>2</value>
          </property>
      </configuration>
      [yarn-site.xml]
      <?xml version="1.0"?>
      <!-- Site specific YARN configuration properties -->
          <property>
              <name>yarn.resourcemanager.hostname</name>
              <value>s201</value>
          </property>
          <property>
              <name>yarn.nodemanager.aux-services</name>
              <value>mapreduce_shuffle</value>
          </property>
      </configuration>
    [slave]
        s202
        s203
        s204
    [hadoop-env.sh]
        export JAVA_HOME=/soft/jdk
    5.分发配置
        $>scp -r full centos@s201:/soft/hadoop/etc/
        $>scp -r full centos@s202:/soft/hadoop/etc/
    6.删除符号连接
        $>cd /soft/hadoop/etc/
        $>rm hadoop
        $>ssh s202 rm /soft/hadoop/etc/hadoop
        $>ssh s203 rm /soft/hadoop/etc/hadoop
    7.创建符号连接
        $>cd /soft/hadoop/etc/
        $>ln -s full hadoop
        $>ssh s202 ln -s /soft/hadoop/etc/full /soft/hadoop/etc/hadoop
        $>ssh s203 ln -s /soft/hadoop/etc/full /soft/hadoop/etc/hadoop
    8.删除临时目录文件
        $>cd /tmp
        $>rm -rf hadoop-centos
        $>ssh s202 rm -rf /tmp/hadoop-centos
        $>ssh s203 rm -rf /tmp/hadoop-centos
    9.删除hadoop日志
        $>cd /soft/hadoop/logs
        $>rm -rf *
        $>ssh s202 rm -rf /soft/hadoop/logs/*
        $>ssh s203 rm -rf /soft/hadoop/logs/*
    10.格式化文件系统
        hadoop namenode -format

rsync
-----------------------
    rsync -lr src desc
    四个机器均安装rsunc命令
    远程同步
    $>sudo yum install rsync

将root用户实现无秘登陆
-----------------------
    1.同

编写脚本
------------------------
    1.xcall.sh
    
    2.xsync.sh
        rsync -lr /home/etc/a.txt    centos@s202:/home/etc
