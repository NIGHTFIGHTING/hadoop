20 Nginx的请求处理流程
-----------------------------------

(1)为什么讨论nginx的架构基础
nginx运行在企业的边缘节点,他处理的流量是应用服务器处理流量的数倍,甚至几个数量级
任何一种问题在不同数量级下的解决方案是不同的.所以在nginx处理场景中,任何一种问题都会被放大

为什么nginx采用master-worker架构模型?
为什么worker进程数量和cpu核数相匹配?
需要在多个worker间共享数据时候,为什么在TSL,或者一些限流限速场景,他们的共享方式是有所不同的?

Nginx请求处理流程:

(1)为什么称为状态机?
因为nginx使用非阻塞的事件驱动处理引擎(epoll),使用异步处理引擎需要使用状态机识别请求和处理

[1]处理4层TCP/UDP的传输层状态机
[2]处理应用的http状态机
[3]处理邮件Mail状态机

(2)每一种状态机在解析出请求,需要访问静态资源时候,对反向代理内容可以做磁盘缓存(proxy_pass,proxy_cache)
处理静态资源问题:当整个内存已经不足以完全缓存住所有的文件,缓存信息,sendfile,aio调用退化为阻塞的磁盘调用,使用线程池处理磁盘阻塞调用

对于每一个处理完的请求,记录access,error日志,记录在磁盘中,也可以通过syslog协议记录在远程机器
Nginx作为负载均衡,反向代理,把请求通过协议级传输后面的服务器,也可以通过应用层协议FastCGI,uWSGI,SCGI(python)代理到应用服务器


21 Nginx的进程结构
-----------------------------------
1.单进程:不适用于生产环境,只适用于开发调试
2.多进程:生成环境保证Nginx足够健壮,Nginx利用多核的特性
父进程:Master Process,子进程:cache,worker进程

为什为多进程结构,不是多线程?
Nginx要保证高可用性,高可靠性.如果使用多线程,线程之间共享同一块地址空间.当一个第三方模块引发一个地址空间导致
段错误时候,会导致整个nginx进程全部挂掉.采用多进程往往不会出现这个问题
第三方模块一般不会在Master Process加入自己代码,Master进程目的worker进程管理,所有的worker进程处理请求,

Master进程监控每个worker进程是否在工作,需不需要载入配置文件,需不需要做热部署
Cache缓存需要在多个Worker进程间共享,还被Cache Manager,Cache Loader进程使用
Cache Manager,Cache Loader为反向代理时候,后端发来的动态请求 做缓存所使用
Cache Loader作为缓存载入
Cache Manager作为缓存管理
这些进程间通信使用共享内存

为什么work进程很多?
Nginx采用事件驱动模型,希望每一个worker进程从头到尾,占有一颗cpu,不仅仅把worker进程数量配置和cpu合数一样
,还需要把每个cpu核与worker进程绑定,可以更好使用每一颗cpu上的cpu缓存,来减少缓存失效命中率

22 Nginx的进程结构实例演示
-----------------------------------
master作为父进程启动很多子进程,Nginx父子进程通过信号管理
ps -ef | grep nginx 看见当前进程id,和进程id
(1)./nginx -s reload把之前的worker,cache进程优雅退出,然后使用新的配置项,启动新的worker进程
reload与SIGHUP信号相同
kill -SIGHUP `cat nginx/logs/nginx.pid`
(2)向worker进程发送退出信号SIGQUIT,SIGINT,SIGTERM,worker进程退出向父进程master发送SIGCHILD信号,master进程知道子进程
退出了,重启一个worker进程

23 使用信号管理Nginx的父子进程
-----------------------------------

Nginx是一个多进程的程序,多进程通信可以使用共享内存,信号等
进程间管理使用信号
Master进程:
(1)监控worker进程CHILD,如果worker模块由于出现bug导致worker进程意外终止,master进程可以立刻通过CHILD信号,
重新把worker进程拉起
(2)接收信号管理worker进程,
TERM,INT立刻停止nginx进程
QUIT优雅停止nginx进程,保证对用户不发送立刻结束连接,不发送TCP-RESET复位请求报文
HUP重载配置文件
USR1重新打开日志文件,做日志文件切割
USR2
WINCH:热部署关闭老的worker进程

为什么不直接对work进程发送信号?
希望通过master进程管理worker进程
work进程
(1)接收信号TERM,INT,QUIT,USR1,WINCH

nginx命令行
启动nginx后,nginx把pid记在logs/nginx.pid,文件中记录master进程pid
执行./nginx -s 命令行,读取pid文件中master进程pid,向进程发送信号
reload:HUP
reopen:USR1
stop:TERM
quit:QUIT

24.reload重载配置文件的真相
-----------------------------------

情况:发现nginx的worker进程数量变多了,因为老配置运行nginx的worker长时间没有退出

(1)向master进程发送HUP信号(reload 命令)
(2)master进程校验配置语法是否正确
(3)master进程打开新的监听端口(子进程会继承父进程打开的所有端口)
(4)master进程用新配置启动新的worker子进程
(5)master进程向老worker子进程发送QUIT信号
(6)老worker进程关闭监听句柄(标志新的连接只会到新的worker),处理完当前连接结束进程

不停机载入新配置,nginx始终保持运行中,平滑的更换了配置文件 
(1)更新nginx.conf配置文件,向Master发送SIGHUP信号或者执行nginx -s reload
(2)Master使用新配置启动新的worker进程
(3)老配置Worker进程在完成已存在连接是优雅的退出

有一些请求出问题,client长时间没有处理,导致请求长时间占用在worker进程上,这个worker进程一直存在,
worker_shutdown_timeout最长会等多长时间,master在启动新的woker子进程时,加上一个定时器,老worker在超时,会强制退出

25.热升级的完整流程
-----------------------------------

热升级流程
(1)将旧Nginx文件换成新Nginx文件(注意备份)
    新编译的nginx所指定配置选项,比如配置目录,log目录必须和老nginx一样
    cp -f nginx nginx.old
(2)向master进程发送USR2信号
       [1]master进程修改pid文件名,加后缀.oldbin
       [2]master进程用新Nginx文件启动新master进程,新的master进程是老master的子进程
       (中间过程,新老nginx进程并存,同时处理请求,然后老master关闭监听端口)
(3)向老master进程发送WINCH信号,关闭老worker
(老的master进程保存下来方便会滚)
(4)[1]回滚:向老master发送HUP,向新master发送QUIT
   [2]向老master进程发送SIGQUIT信号,要求它优雅的停止 


26 优雅地关闭worker进程
-------------------------------------
(1)设置定时器worker_shutdown_timeout
(2)关闭监听句柄
(3)闭空闲连接(看nginx连接池,nginx保证资源利用最大化,经常保存一些连接,没有断开)
(4)在循环中等待全部连接关闭,或者等到worker_shutdown_timeout时间立即退出
(5)退出进程 

如果我们在处理连接的时候,不管连接此时是怎样的作用,直接关闭连接,会导致用户收到错误
优雅的关闭:(1)只nginx可以识别出当前的连接没有正在处理请求,这时把连接关闭
           (2)有些情况nginx做不到,
               比如nginx代理websocket协议,websocket后面通讯的fram帧里面,nginx不解析帧
               nginx做tcp/udp反向代理,nginx没有办法识别需要经过多少报文才算是结束
               主要是针对http请求
                                  
在特性失效时候考虑nginx有无能力判定一个连接应当被正确关掉
或者说一些模块,或客户端不能正常处理请求时,nginx需要有一些措施,比如worker_shutdown_timeout保证worker进程退出

27 网络收发与Nginx事件间的对应关系
---------------------------------------

事件->网络事件

应用层发起get请求
传输层,浏览器打开端口,把端口记下来,把nginx打开的端口记录在传输层
网络层我的主机ip,以及nginx所在服务器公网ip
链路层
路由器,会记录我家所在运营商的ip

网络报文角色:
数据链路层在HEADER和FOOTER添加MAC地址,源MAC地址,目的MAC地址
网络层:源IP地址,nginx公网地址(目的IP地址),MTU以太网1500K
传输层:浏览器打开的端口,nginx端口,TCP层考虑中间每一个环节最大MTU值,MSS
应用层:http协议

读事件
(1)请求建立TCP连接事件
(2)TCP连接可读事件
(3)TCP连接关闭事件
写事件:nginx需要向浏览器发送响应,需要把消息写到操作系统中,要求操作系统发到网路中
异步处理时间框架中:事件收集分发器,定义每一个事件的消费者,事件是生产者
读消息写消息,在http状态机,不同时间段调用不同方法


28 Nginx网络事件实例演示
---------------------------------------

29 Nginx的事件驱动模型
-----------------------------------------

WAIT FOR EVENTS ON CONNECTIONS
等待事件:比如客户端连接nginx,对应epoll_wait方法,nginx处理sleep状态
当操作系统收到一个TCP建立连接的握手报文,并且处理完握手流程以后,操作系统通知epoll_wait阻塞方法,唤醒nginx的worker进程
    |
   \|/
REVEIVE QUEUE OF NW EVENTS <----- KERNEL
找操作系统要事件,操作系统把事件放在事件队列中
    |                               /|\
   \|/                               |
PROCESS THE EVENT QUEUE IN CYCLE------
处理事件循环 

                        No
IS EVENTS QUEUE EMPTY -------> QUEUE
事件队列不为空,取出事件,处理事件
处理事件过程中可能会生成新的事件,比如一个连接新建立,需要添加一个超时时间,默认60s,如果浏览器不像我发送请求,关闭连接
比如收完完整http请求,可以生成http响应,需要向操作系统写缓冲区,要求操作系统把缓冲区内容发送给浏览器

如果所有事件处理完回到WAIT FOR EVENTS ON CONNECTIONS

一些第三方模块大量运算,处理一个事件非常长,会导致后续队列中大量事件长时间得不到处理,从而引发恶性循环
大量cpu,nginx任务都消耗在处理连接不正常断开,所以nginx不能容忍第三方模块长时间消耗大量cpu进行计算任务
比如gzip不会一次使用大量cpu,都是分段适用的


30 epoll的优劣及原理
------------------------------------

比如nginx要处理100w连接,每两次在等待连接中,时间可能非常短,短短几百ms所能收到的报文数量是有限的,有限的事件对应
的连接也是有限的(每次处理时间时,虽然有100W个并发连接,可能直接接收到几百个活跃连接)
select,poll每次在取操作系统事件时,把这100W个连接扔给操作系统,让它一次判断哪些连接有事件进来,
操作系统做了无用功,扫描了大量无用连接
epoll利用这个特性,每次处理活跃连接占比很小
nginx每次取活跃连接时,只需遍历一个链表,这个链表仅仅只有活跃的连接
比如:nginx收到80端口建立连接请求,80端口建立成功后,添加一个读事件,用于读取http消息,事件添加到一个红黑树中,
二叉平衡树插入效率O(log(n)),如果现在不想处理读事件,写事件,从平衡二叉树移除节点
读取一个事件链表数量减少,当操作系统从网卡接收到发来的报文链表增加

eventpoll,rdllist,rdr


31 Nginx的请求切换
-----------------------------------------

事件驱动对于请求切换的收益

TRADITIONAL_SERVER:比如三个http请求,请求分为3部分:1.收完http请求header,知道给上游哪一台服务器处理,通过负载均衡算法,
接下来可能向上游服务器建立连接.或者本地处理,判断header中有无content-length,指明含有body.如果含有body,去读下一个
读事件,处理完http body,会发送响应
比如Apache每一个进程同时支处理一个连接
(1)不做连接切换
(2)依赖OS的进程调度实现并发
,当process 1目前网络事件不满足,切换到process 2处理request 2,request 2不满足比如写缓存区满了,网络比较拥塞,滑动窗口没有向前滑动,以至于调用write方法,没有写入我们需要写入的字节,当write方法为
非阻塞时候,这时候阻塞的write方法导致进行一次进程间切换,切换到process 3,执行一段时间,可能用完事件片
进行一次进程切换.每一次进程切换大约5ms,如果并发连接并发进程数增加,指数增加
操作系统调用仅适用成百上千进程间切换
时间片的长度一般是5ms~800ms
nginx的worker进程优先级调的比较高如-19,操作系统给我们分的时间片比较大.nginx可以叫较好完成用户态切换,
是的CPU少做无用功


32 同步&异步、阻塞&非阻塞之间的区别
-----------------------------------------------
阻塞与非阻塞指操作系统或底层C库方法或者一个系统调用,
阻塞方法:
调用这个方法导致一个进程进入sleep状态.
当前条件不满足情况下,操作系统主动把我的进程切换为另一个进程使用当前CPU
非阻塞方法:
不会因为当我们事件片未用完时,把我们进程主动切换掉

同步异步调用方式,编码写我们业务逻辑角度
nginx除了官方通过javascript同步携代码方式实现,实现非阻塞编码效果.以及openresty基于lua语言使用同步语言,实现
非阻塞高并发效果

以accept为例
阻塞调用:使用阻塞socket
如果监听的port,所对应的accept队列(操作系统已经做好三次握手,建立成功的socket),阻塞方法可能会得到立刻返回,不会被阻塞.
如果accept队列为空,操作系用会等待三次握手的连接,到达内核中,唤醒accept调用.时间可控,可以设置阻塞socket最长超时时间
产生主动进程切换

非阻塞调用:使用非阻塞socket
如果accept队列为空,不等待,立刻返回EAGAIN错误
如果accept队列不为空,不等待立刻返回,成功间socket从ACCEPT队列中移除并拷贝给进程
由你的代码决定是否切换新任务
由你的代码决定,当收到EAGIN错误码,是等一会继续处理这个连接,还是切换到其他任务在处理

(1)nginx作为反向代理特点:考虑上游服务处理能力不足,如果有body的http请求,http先接收完body,在向上游服务器发起连接
收完header已经知道向哪台上游服务器建立连接.但是先读取body
表示执行完ngx_http_read_request_body后,再去回调post_handler(ngx_http_upstream_init),
ngx_http_upstream_init是对上游服务器建立连接方法
rc = ngx_http_read_request_body(r, ngx_http_upstream_init)
if (rc >= NGX_HTTP_SPECIAL_RESPONSE) {
    return tc;
}

(2)connect没有被满足,没有收到redis发来的响应,connect不会返回,不会阻塞nginx代码
local client = redis:new()
client:set_timeout(30000)
local ok,err = client:connect(ip,port)
if not ok then
    ngx.say("failed:", err)
    return
end

33 Nginx的模块究竟是什么？
------------------------------------
http://nginx.org/en/docs/http/ngx_http_gzip_module.html
前提编译进Nginx
提供哪些配置项
模块合适被使用
提供哪些变量:Embedded Variables
./condfigure --with --without --add-module
确认编译进nginx中,objs/ngx_modules.c,ngx_modules[]包含所有编译间nginx模块
确认模块提供哪些指令?ngx_command_t包含支持的指令名,表明后面可以跟几个参数,参数为什么样类型

ngx_modult_t定义所有模块顺序,模块有冲突,先生效的模块会阻碍后生效的模块发挥作用
高内聚:相应独立的功能是在同一个模块代码块中
抽象:ngx_modult_t里的ngx_command_t定义配置.启停回调方法
init_master,init_module,init_process,init_thread,exit_thread,exit_process,exit_master
子模块抽象:http,event,mail,stream

34 Nginx模块的分类
---------------------------------------------
ngx_modult_t中变量type标志属于哪一个类型模块
NGX_CORE_MODULE:核心模块,通过某一类core_module,独立定义出新的子类型模块
NGX_EVENT_MODULE:所有事件处理,每一类模块存在通用共性部分,会在第一个模块_core关键字
每一个子类型中,事件模块,_core文件定义所有子类型模块,共有的特性
NGX_CONF_MODULE:解析nginx的conf文件
NGX_HTTP_MODULE:ngx_http_core_module,请求处理模块,响应过滤模块(对response的文件做特定处理,对css文件gzip压缩,
对图片做裁剪,把response做二次处理),upstream相关模块(nginx作为反向/正向代理把请求传给服务做处理)
NGX_STREAM_MODULE:
NGX_MAIL_MODULE:

core:nginx核心框架代码
event:
http:还会有一些框架代码,复制核心流程,每一个模块都有一个核心模块,定义了http模块工作方式
http/modules:可有可无1.处理请求生成响应2.响应过滤,文件名有filter3.与上游服务器发生交互,文件名upstream4.为生成响应工作
stream:
看一下第三方模块属于哪一个模块

35 Nginx如何通过连接池处理网络请求
-----------------------------------------------
每个worker进程都含有ngx_cycle_t结构
http://nginx.org/en/docs/ngx_core_module.html#worker_connections
这个连接不仅用于客户端连接,也用于上游服务器
ngx_cycle_t->connections,配置worker_connections默认nginx 512
read_events,write_events与worker_connections一样大
配置更多的worker_connections会使用更大内存
struct ngx_connections {
    ngx_event_t* read; // 读事件
    ngx_event_t* write; // 写事件
    ngx_recv_pt recv;
    ngx_recv_pt send; // 抽象解耦OS底层方法
    off_t sent; // 这个连接上已经发送多少字节 看做unsigned int, 内置变量bytes_sent变量(ngx_http_core_module)
};232+96*2
struct ngx_events {
    ngx_evnet_handler_pt handler; // 事件回调
    ngx_rbtre_node_t timer; // http请求读写超时,nginx实现超时定时器
    ngx_queue_t queue; // 多个事件形成队列
};96字节

http://nginx.org/en/docs/http/ngx_http_core_module.html
client_header_timeout 60s
[$request_length:$bytes_sent]

配置高并发nginx需要配置并发足够大,每个connection对应的event会消耗一定的内存,
nginx的一些成员可以与内置变量相对应bytes_sent,body_bytes_sent

36 内存池对性能的影响
----------------------------------------------------

基础同步工具:信号,共享内存
nginx的worker进行数据同步使用共享内存,比如打开一块共享内存10m,0~10m之间,多个worker之间可以同时访问他,包括
读取和写入.多个worker同时操作一块内存存在竞争关系,

信号量:导致进程进入休眠状态,进程主动切换
加入这把锁,锁住一扇门,worker进程1拿到这把锁进入屋里,worker进程2试图拿锁,敲门里面有人了,会就地休息,
等待worker进程1出来通知他

自旋锁:当这个锁的条件,没有满足.块内存现在被1号worker使用,2号进程获取锁的时候,只要1号进程没有释放锁
,2号进程会一直请求这把锁
worker进程2发现门里有worker进程1,会持续的敲门
所以使用自旋锁的nginx模块,需要快速的使用共享内存.快速使用锁释放锁.一旦有第三方模块不遵守,导致出现死锁,或性能下降

一整块共享内存给多个worker同时使用的,在模块中手动的编写分配把这些给到不同对象,是非常繁琐的->slab内存管理器

限速,流控不能容忍在内存中做.比如一个worker进程对某一个用户出发流控,其他worker进程还不知道,只能在共享内存中做
,limit_conn,limit_req,http cache,ssl使用rbtree,插入删除速度很快(对一个客户端限速,速度达到了,把客户端从
限速数据结构中移除)

单链表:把需要共享的元素串起来ngx_http_upstream_zone_module,

lua_shared_dict:
rbtree:使用红黑树保存每一个key->value;因为10m是有限的,
list:lua代码设计到我们应用代码,易超出10m限制,采用lru淘汰,最早set/get
长时间不用的节点优先被淘汰

共享内存是跨worker通讯,一个业务逻辑在多个worker间共同生效,集群流控

38 用好共享内存的工具 Slab管理器
-----------------------------------------------

Bestfit:最多两倍内存消耗
适合小对象,避免碎片,避免重复初始化

共享内存可以使用rbtree,list数据结构,每一个rbtree有很多节点,每个节点都需要分配内存存放.怎样把一整块共享内存,切割成小块,给红黑树上每一个节点使用

stable内存管理用于共享内存,把共享内存分为许多页面i,32,64,128字节,这些slot以乘2方式向上增长.
51会分配小于它最大的环节64字节,存在内存浪费

如果我们分配内存非常小,小于一个页面大小,很少有碎片.没分配一块内存就是沿着还未分配空白的地方继续使用,当一个页面使用完,拿一个空闲页面继续给此类slot大小内存继续使用
一些数据结构固定的,并且需要初始化,避免重复初始化
用于openresty,limit_req,limit_conn
ngx_slab_stat:统计slat使用状态
tegine/modules/ngx_slab_stat

http://tengine.taobao.org/download.html
./configure --add-module=/root/tengine-2.3.0/modules/ngx_slab_stat

curl localhost:80/set
curl localhost:80/get
curl localhost:80/slab_stat

10m是一个非常大一个共享内存,划分为很多页面,对于比较小的32Bytes,一个页面可以有128个


39 哈希表的max_size与bucket_size如何配置
----------------------------------------------------
数组:ngx_array_t多块连续内存,每块连续内存可以存放许多元素
链表:ngx_list_t
队列:ngx_queue_t
哈希表:
每一个元素会顺序放在一块连续内存中,每一个key通过hash函数映射的
应用场景不同,静态不变的内容,运行过程中,不会出现插入删除.nginx刚启动可以确认hash表有多少个元素.
Max size控制最大hash表bucket个数,不是实际上hash表bucket个数.作用限制最大化的使用
stream/http:variables变量(在模块编译的时候确定了),map,http proxy(定义在配置文件中header做hash)
Bucket size有默认值cpu cache line对齐,主流cpu有l1,l2,l3缓存,再取主存内存上数据时,
主流cpu取主存字节数是cpu cache line(64Bytes),为什么hash表向64字节对齐
假设hash表每一个bucket是59字节,如果是紧密排列在一起,取第一个元素取1次,多取1Bytes,在取第二个元素,
需要访问主存两次,包含第一个64字节的64Bytes,第二个单元的58字节.
为了避免去两次,nginx代码做了向上对齐
bucket size:如果配置的不是cpu cache line,比如分配70字节,向上配置128字节
            有可能尽量不超过64Bytes,以减少cpu访问每个hash表次数

遍历复杂度:buckets数量

哈希表:
基数数:自平衡平衡二叉树,key只能是整形,geo模块使用

40 Nginx中最常用的容器 红黑树
--------------------------------------------------------
nginx多个worker间进行进行间通信,经常使用红黑树管理许多对象.nginx内存也会使用rbtree
ngx_rbtree_t:自平衡二叉查找树,高度不会超过2被log(n),增删改查算法复杂度O(log(n)),遍历复杂度O(n)

内存中使用红黑树:ngx_conf_module(cofig_dump_rbtree),ngx_event_timer_rbtree定时器,
基于共享内存使用红黑树:ngx_http_file_cache,ngx_http_geo_module,ngx_limit_conn_module,ngx_http_limit_req_module
                       ngx_http_lua_shdict:ngx.shared.dict LRU链表


41 使用动态模块来提升运维效率
-------------------------------------------------------

ngxin动态模块,nginx升级减少编译环节
yum -y install gd-devel

静态库:把所有源代码编译进最终的binary可执行文件中
动态库:bianry文件只保留它的位置(地址),当需要动态库功能时,有nginx可执行文件调用动态库.当我仅仅需求升级某个模块功能时,
特别当nginx编译大量第三方模块,仅仅重新编译这个动态库,而不用替换bianry文件.新的动态库替换,新的nginx reload使用新的模块功能

(1)Configure加入动态模块./configure --prefix=/home/centos/nginx1 --with-http_image_filter_module=dynamic,不是所有nginx模块都可以加入nginx中
(2)编译进binary
(3)启动时初始化模块数组,读取ngx_modules数组,发现使用一个动态模块
(4)读取load_module配置,nginx.conf指明动态模块路径
(5)打开动态库并加入模块数组
(6)基于模块数组开始初始化

(1)load_module modules/ngx_http_image_filter_module.so;
(2)        location / { 
            root   test;
            image_filter resize 15 10; 
        }
(3)./nginx -s reload
(4)curl http://192.168.244.131:8080/hdfs-write.png
nginx在编译太多模块,参数及其复杂场景,可以减少出错概率
