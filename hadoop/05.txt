hdfs
--------------------
    write过程


block
--------------------
    文件块
    128M
    最小块:1m
    dfs.blocksize=


packet
--------------------
    包
    64k

chunk
--------------------
    小块
    512bytes



clien -> namenode
  |
 \|/
dataqueue->checksum->dn1->dn2->dn3
  |                             |
 \|/                            |
ackqueue<------------------------


namenode存放的是filesystem的元数据(路径+副本个数+块大小+权限)
fault tolerance    // 容错
fail over    // 容灾

副本的放置
--------------------
    副本放置的机架感知目的可靠性,可用性,提升网络性能.

自定义机架感知
--------------------
    http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/RackAwareness.html
    1.实现org.apache.hadoop.net.DNSToSwitchMapping
        package com.it18zhang.myhadoop_maven;
        
        import java.util.List;
        import java.util.ArrayList;
        import org.apache.hadop.net.DNSToSwitchMapping;
        
        
        /**
         *机架感知
         **/
        
        public class MyDNSToSwitchMapping implements DNSToSwitchMapping {
        
            public List<String> resolve(List<String> names) {
                List<String> list = new ArrayList<String>();
                for (String name : names) {
                    Integer ip = null;
                    if (name.startsWith("192")) {
                        ip =  Integer.parseInt(name.substring(name.lastIndexOf("." + 1)));
                    } else {
                        ip = Integer.parseInt(name.substring(1));
                    }
                    if (ip <= 202) {
                        list.add("/rack1/S" + ip);
                    } else {
                        list.add("/rack2/s" + ip);
                    }
                }
                return null;
            }
        
            public void reloadCachedMappings() {
                // TODO Auto-generated method stub
        
            }
        
            public void reloadCachedMappings(List<String> names) {
                // TODO Auto-generated method stub
        
            }
        
        }

    2.配置core-site.xml
        <property>
            <name>net.topology.node.switch.mapping.impl</name>
            <value>com.it18zhang.myhadoop_maven.MyDNSToSwitchMapping</value>
        </property>
    3.导出jar
        使用eclipse的maven build菜单实现到处jar.
        跳过测试
        clean package -DskipTests
    4.分发jar和配置文件到集群
         myhadoop_maven-0.0.1-SNAPSHOT.jar分发到${hadoop_home}/soft/hadoop/share/hadoop/common/lib
         core-site.xml分发到${hadoop_home}/soft/hadoop/etc/hadoop/

[rack1] 
192.168.244.131    s201
192.168.244.129    s202

[rack2]
192.168.244.130    s203


作业
---------------------
    1.熟悉hdfs文件写入过程原理
    2.参照写入过程把读取过程的uml时序图制作出来
