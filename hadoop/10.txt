大数据
---------------
    0.分布式
        由分布在**不同主机**上的进程**协同**在一起构成整个应用
        block.
    1.存储
        分布式存储
    2.计算
        分布式计算


管理hadoop
----------------
    1.配额
        空间配额
        目录配额
    2.快照
        snapshot
    3.回收站
        trash    //
    4.上下线
         dfs.hosts    // hdfs
         dfs.hosts.exclude    // hdfs

GFS
----------------
    google file system         

Mysql:OLTP

MR
----------------
    MapReduce
    映射和化简
    编程模型

 
alt>s>v
ctrl+3

使用mr计算年度的最高气温
-----------------------------
    1.1901.gz + 1902.gz
    2.编写mapper
        [MaxTempMapper.java]
        package com.it18zhang.mapreduce;
        
        import java.io.IOException;
        
        import org.apache.hadoop.io.IntWritable;
        import org.apache.hadoop.io.LongWritable;
        import org.apache.hadoop.io.Text;
        import org.apache.hadoop.mapreduce.Mapper;
        /**
         * MR:Map
         **/
        public class MaxTempMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
        
            // 缺失常量
            public static final int MISSING = 9999;
            @Override
            protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, IntWritable>.Context context)
                    throws IOException, InterruptedException {
                // 取得一整行文本
                String line = value.toString();
                // 提取年分值
                String year = line.substring(15, 19);
                // 定义气温变量
                int airTemperature;
                // 取出气温
                if (line.charAt(87) == '+') {
                    airTemperature = Integer.parseInt(line.substring(88, 92));
                } else {
                    airTemperature = Integer.parseInt(line.substring(87, 92)); 
                }
                // 提取质量
                String quality = line.substring(92, 93);
                
                if (airTemperature != MISSING && quality.matches("[01459]")) {
                    context.write(new Text(year), new IntWritable(airTemperature));
                }
            }
        
        }
        
    3.编写reducer
        [MaxTempReducer.java]
        package com.it18zhang.mapreduce;

        import org.apache.hadoop.mapreduce.Reducer;
        import java.io.IOException;
        import org.apache.hadoop.io.IntWritable;
        import org.apache.hadoop.io.Text;
        
        /**
         * MR:Reduce
         **/
        
        public class MaxTempReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
        
            @Override
            protected void reduce(Text key, Iterable<IntWritable> values,
                    Reducer<Text, IntWritable, Text, IntWritable>.Context context) throws IOException, InterruptedException {
                // 最大值
                int maxValue = Integer.MIN_VALUE;
                // 提取年份的最大值
                for (IntWritable value : values) {
                    maxValue = Math.max(maxValue, value.get());
                }
                // output key maxValue
                context.write(key, new IntWritable(maxValue));
            }
        
        }
    4.编写
        [App.java]
        public class App {
  
         public static void main(String[] args) {
             if (args.length != 2) {
                 System.err.println("Usage: MaxTemperature <input path> <output path>");
             }
             try {
                 // 创建配置对象
                 Configuration conf = new Configuration();
                 // 创建job对象
                 Job job = Job.getInstance(conf);
                 
                 // 设置jar搜索类
                 job.setJarByClass(App.class);
                 // 设置作业名称
                 
                 // 添加输入路径
                 FileInputFormat.addInputPath(job, new Path(args[0]));
                 
                 // 设置输出路径
                 FileOutputFormat.setOutputPath(job, new Path(args[1]));
                 //设置Mapper类型
                 job.setMapperClass(MaxTempMapper.class);
                 //设置Reducer类型
                 job.setReducerClass(MaxTempReducer.class);
                 //设置输出key类型
                 job.setOutputKeyClass(Text.class);
                 //设置输出Value类型
                 job.setOutputValueClass(IntWritable.class);
                 System.exit(job.waitForCompletion(true) ? 0 : 1);
             } catch (Exception e) {
                 
             }
         }
     
     }
     5.导出jar包
         mapreduce-0.0.1-SNAPSHOT.jar
     6.put天气文件到hdfs
     7.复制mapreduce-0.0.1-SNAPSHOT.jar到共享目录
     8.启动yarn进程
         $>start-yarn.sh
     9.验证
         $>xcall.sh jps
     10.执行hadoop jar进行mr作业
         $>hadoop jar mapreduce-0.0.1-SNAPSHOT.jar com.it18zhang.mapreduce.App /user/centos/hadoop/data /user/centos/hadoop/out

$>yarn-daemon.sh stop nodemanager
